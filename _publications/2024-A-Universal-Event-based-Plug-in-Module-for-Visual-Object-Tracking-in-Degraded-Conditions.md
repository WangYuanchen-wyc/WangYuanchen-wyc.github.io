---
title: "A Universal Event-based Plug-in Module for Visual Object Tracking in Degraded Conditions"
collection: publications
permalink: /publication/2024-A-Universal-Event-based-Plug-in-Module-for-Visual-Object-Tracking-in-Degraded-Conditions
excerpt: 'Object Tracking'
date: 2024
venue: 'IJCV'
paperurl: 'http://WangYuanchen-wyc.github.io/files/IJCV 2024.pdf'
citation: 'Zhang J, Dong B, Fu Y, et al. A Universal Event-Based Plug-In Module for Visual Object Tracking in Degraded Conditions[J]. International Journal of Computer Vision, 2024, 132(5): 1857-1879.'
---
## Input-Output
Given the first frame image, and it is corresponding events and bounding box, our network produces the following bounding boxes.
## Abstract
Most existing trackers based on RGB/grayscale frames may collapse due to the unreliability of conventional sensors in some challenging scenarios (e.g., motion blur and high dynamic range). Event-based cameras as bioinspired sensors encode brightness changes with high temporal resolution and high dynamic range, thereby providing considerable potential for tracking under degraded conditions. Nevertheless, events lack the fine-grained texture cues provided by RGB/grayscale frames. This complementarity encourages us to fuse visual cues from the frame and event domains for robust object tracking under various challenging conditions. In this paper, we propose a novel event feature extractor to capture spatiotemporal features with motion cues from event-based data by boosting interactions and distinguishing alterations between states at different moments.
